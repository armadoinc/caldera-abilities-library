- id: f313a0d7-2327-4f69-8da4-a6efd6135121
  name: Hash Sensitive Files
  description: Acquire hashes of sensitive files as a baseline to check if they are
    changed in the future
  tactic: setup
  technique:
    attack_id: x
    name: x
  repeatable: false
  platforms:
    linux:
      sh:
        command: "output=\"\";\nfilepath=$(echo \"#{file.sensitive.path}\" | sed 's/\\\
          \\\\*/\\*/g');\nfiles=$(find $filepath -maxdepth 0 -type f 2>/dev/null);\n\
          for file in $files;\n  do hash=$(sha256sum $file | cut -d' ' -f1);\n  output=\"\
          ${output}${file}>${hash}\\n\";\ndone;\necho $output | sed '/^[[:space:]]*$/d'\n"
        parsers:
          plugins.response.app.parsers.key_value:
          - source: file.sensitive.path
            edge: has_hash
            target: file.sensitive.hash
    darwin:
      sh:
        command: "output=\"\";\nfilepath=$(echo \"#{file.sensitive.path}\" | sed 's/\\\
          \\\\*/\\*/g');\nfiles=$(find $filepath -maxdepth 0 -type f 2>/dev/null);\n\
          for file in $files;\n  do hash=$(shasum -a 256 $file | cut -d' ' -f1);\n\
          \  output=\"${output}${file}>${hash}\\n\";\ndone;\necho $output | sed '/^[[:space:]]*$/d'\n"
        parsers:
          plugins.response.app.parsers.key_value:
          - source: file.sensitive.path
            edge: has_hash
            target: file.sensitive.hash
    windows:
      psh:
        command: 'Get-FileHash #{file.sensitive.path} -EA silentlycontinue | foreach-object
          {$_.Path + ''>'' + $_.Hash}

          '
        parsers:
          plugins.response.app.parsers.key_value:
          - source: file.sensitive.path
            edge: has_hash
            target: file.sensitive.hash
  requirements:
  - plugins.response.app.requirements.source_fact:
    - source: file.sensitive.path
